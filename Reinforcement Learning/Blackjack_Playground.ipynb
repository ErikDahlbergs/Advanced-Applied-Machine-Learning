{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Rp1SbdEPmm"
      },
      "source": [
        "# Playground for the Env\n",
        "This is a quick playground to better understand how the environment works. While it contains no mandatory elements, we recommend you to go through it before starting implementing your agent.\n",
        "\n",
        "The provided code for the blackjack Env is automatically downloaded from https://raw.githubusercontent.com/volkerkrueger/RL-Lab/master/blackjack.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dcr3gJGfbSVJ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gym'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mblackjack\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotting\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/1. LTH/Avancerad MaskininlaÌˆrning/Labbar/lab4/blackjack.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seeding\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "array = np.array([1,2])\n",
        "import blackjack\n",
        "import plotting\n",
        "import sys\n",
        "from blackjack import BlackjackEnv\n",
        "try:\n",
        "    # Check if notebook is running in Google Colab\n",
        "    #import google.colab\n",
        "    # Get additional files from Github\n",
        "    #!wget https://raw.githubusercontent.com/volkerkrueger/RL-Lab/master/blackjack.py\n",
        "    #!wget https://raw.githubusercontent.com/volkerkrueger/RL-Lab/master/plotting.py\n",
        "    # Install additional dependencies\n",
        "    print(\"sucess\")\n",
        "except:\n",
        "    print(\"failed\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO56WIueEc5m"
      },
      "source": [
        "# The environment\n",
        "\n",
        "In reinforcement learning it is common practice to represent the task that we are working with as a Gymnasium environment (https://gymnasium.farama.org/index.html). The environment provides a number of the convenience features, making it easy to run sessions to train your RL agent.\n",
        "\n",
        "Most notably, each env has a a `.reset()` routine that starts a new session, returning the initial observation and a `.step(action)` that returns the new observation and the action reward among others.\n",
        "\n",
        "Gymnasium comes with a number if predefined environments, but you can also create your own, such as in this case the BlackJack Environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpWW97dubSVJ"
      },
      "outputs": [],
      "source": [
        "env = BlackjackEnv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-EUzXbzEh9Q"
      },
      "source": [
        "# Playing around with the Env\n",
        "\n",
        "Here we provide some code defines a simple strategy and tests it against the environment. Before starting the lab make certain you understand how the environment works, and how the observation and actions spaces look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC86SWnBbSVJ"
      },
      "outputs": [],
      "source": [
        "def print_observation(observation):\n",
        "    score, dealer_score, usable_ace = observation\n",
        "    print(\"Player Score: {} (Usable Ace: {}), Dealer Score: {}\".format(\n",
        "          score, usable_ace, dealer_score))\n",
        "\n",
        "def strategy(observation):\n",
        "    score, dealer_score, usable_ace = observation\n",
        "    # Stick (action 0) if the score is > 20, hit (action 1) otherwise\n",
        "    return 0 if score >= 20 else 1\n",
        "\n",
        "for i_episode in range(20):\n",
        "    observation = env.reset()\n",
        "    for t in range(100):\n",
        "        print_observation(observation)\n",
        "        action = strategy(observation)\n",
        "        print(\"Taking action: {}\".format( [\"Stick\", \"Hit\"][action]))\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "            print_observation(observation)\n",
        "            print(\"Game end. Reward: {}\\n\".format(float(reward)))\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOLkDewbbSVJ"
      },
      "outputs": [],
      "source": [
        "observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZWWMIrdbSVK"
      },
      "outputs": [],
      "source": [
        "observation = env.reset()\n",
        "print_observation(observation)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
