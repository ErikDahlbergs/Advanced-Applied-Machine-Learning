{"cells":[{"cell_type":"markdown","metadata":{"id":"tp9AxT376Fdi"},"source":["# NLP Assignment: Extraction of Named Entities\n","Author: Pierre Nugues"]},{"cell_type":"markdown","metadata":{"id":"p9__q-h66Fdl"},"source":["In this assignment, you will create a system to extract named entities from a text. You will use the CoNLL 2003 dataset and you will train your models with PyTorch.\n","\n","Be aware that with PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n","\n","Before you start the assignment, please run the prerequistites notebook. The 100d vectors should give better results than the 50d, but they take a longer time to train. Start with the 50d vectors. Then, optionally, run the experiments with 100d vectors, if your machine is fast enough."]},{"cell_type":"markdown","metadata":{"id":"hGZrAU5a6Fdm"},"source":["## Objectives"]},{"cell_type":"markdown","metadata":{"id":"xfuQ7e5o6Fdm"},"source":["The objectives of this assignment are to:\n","* Write a program to recognize named entities in text\n","* Learn how to manage a text data set\n","* Apply recurrent neural networks to text with PyTorch\n","* Know what word embeddings are\n","* Write a short report of 2 to 3 pages on your experiments. This report is mandatory to pass the assignment."]},{"cell_type":"markdown","metadata":{"id":"THyNad8M6Fdn"},"source":["## Organization and location"]},{"cell_type":"markdown","metadata":{"id":"-5r-Grbf6Fdn"},"source":["You can work alone or collaborate with another student:\n","* Each group will have to write Python programs to recognize named entities in text.\n","* You will have to experiment different architectures, namely RNN and LSTM, and compare the results you obtained.\n","* Each student will have to write an individual report on these experiments."]},{"cell_type":"markdown","metadata":{"id":"cPbe2eiw6Fdn"},"source":["## Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"VuNgymsX6Fdn"},"source":["### Imports\n","For the vector and matrix operations, use pytorch only. __Do not use numpy__."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"-LOgOkwW6Fdp"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import os\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import conlleval"]},{"cell_type":"markdown","metadata":{"id":"xOdT7khp6Fdp"},"source":["### Seeds\n","Making things reproduceable"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"lKQcCvKb6Fdp"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x13bbe4030>"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["random.seed(1234)\n","torch.manual_seed(1234)"]},{"cell_type":"markdown","metadata":{"id":"u4VC_SUy6Fdq"},"source":["### Constants"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"u42SKFLz6Fdq"},"outputs":[],"source":["EPOCHS = 20\n","MOD = 2\n","LSTM_HIDDEN_DIM = 98 if MOD == 2 else 64\n","LSTM_LAYERS = 3 if MOD == 2 else 2\n","DROPOUT = 0.4 if MOD == 2 else 0.3\n","EMB_LARGE = True # GloVe 50 or 100\n","FREEZE_EMBS = True\n","LARGE_MEM = False\n","LSTM = True # Toggle between LSTM and RNN\n","RETRAIN = 0"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"chXOeoz36Fdq"},"outputs":[],"source":["config = {'EPOCHS': EPOCHS,\n","'LSTM_HIDDEN_DIM': LSTM_HIDDEN_DIM,\n","'LSTM_LAYERS': LSTM_LAYERS,\n","'DROPOUT': DROPOUT,\n","'EMB_LARGE': EMB_LARGE,\n","'FREEZE_EMBS': FREEZE_EMBS,\n","'LSTM': LSTM}"]},{"cell_type":"markdown","metadata":{"id":"xs5C0Z3P6Fdq"},"source":["### The datasets"]},{"cell_type":"markdown","metadata":{"id":"BCHLtOw76Fdq"},"source":["You may need to adjust the paths to load the datasets from your machine."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"C6EqZ2eu6Fdq"},"outputs":[],"source":["train_file = \"./conll2003/train.txt\"\n","val_file = \"./conll2003/valid.txt\"\n","test_file = \"./conll2003/test.txt\""]},{"cell_type":"markdown","metadata":{"id":"HLpqHHlq6Fdr"},"source":["## Reading the files"]},{"cell_type":"markdown","metadata":{"id":"lqhS6NIQ6Fdr"},"source":["You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."]},{"cell_type":"code","execution_count":63,"metadata":{"id":"aYXENlsk6Fdr"},"outputs":[],"source":["def read_sentences(file):\n","    \"\"\"\n","    Creates a list of sentences from the corpus\n","    Each sentence is a string\n","    :param file:\n","    :return:\n","    \"\"\"\n","    f = open(file).read().strip()\n","    sentences = f.split('\\n\\n')\n","    return sentences"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"sh3-J7LL6Fdr"},"outputs":[],"source":["def split_rows(sentences, column_names):\n","    \"\"\"\n","    Creates a list of sentences where each sentence is a list of lines\n","    Each line is a dictionary of columns\n","    :param sentences:\n","    :param column_names:\n","    :return:\n","    \"\"\"\n","    new_sentences = []\n","    for sentence in sentences:\n","        rows = sentence.split('\\n')\n","        sentence = [dict(zip(column_names, row.split())) for row in rows]\n","        new_sentences.append(sentence)\n","    return new_sentences"]},{"cell_type":"markdown","metadata":{"id":"JTRDkik66Fdr"},"source":["### Loading dictionaries"]},{"cell_type":"markdown","metadata":{"id":"frEI3HiP6Fdr"},"source":["The CoNLL 2002 files have four columns: The wordform, `form`, its predicted part of speech, `ppos`, the predicted tag denoting the syntactic group also called the chunk tag, `pchunk`, and finally the named entity tag `ner`."]},{"cell_type":"code","execution_count":65,"metadata":{"id":"rH_9jvQu6Fdr"},"outputs":[],"source":["column_names = ['form', 'ppos', 'pchunk', 'ner']"]},{"cell_type":"markdown","metadata":{"id":"AbfdyRBN6Fdr"},"source":["We load the corpus as a list of dictionaries"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"8a93kv0l6Fdr"},"outputs":[{"data":{"text/plain":["[{'form': 'EU', 'ppos': 'NNP', 'pchunk': 'B-NP', 'ner': 'B-ORG'},\n"," {'form': 'rejects', 'ppos': 'VBZ', 'pchunk': 'B-VP', 'ner': 'O'},\n"," {'form': 'German', 'ppos': 'JJ', 'pchunk': 'B-NP', 'ner': 'B-MISC'},\n"," {'form': 'call', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'},\n"," {'form': 'to', 'ppos': 'TO', 'pchunk': 'B-VP', 'ner': 'O'},\n"," {'form': 'boycott', 'ppos': 'VB', 'pchunk': 'I-VP', 'ner': 'O'},\n"," {'form': 'British', 'ppos': 'JJ', 'pchunk': 'B-NP', 'ner': 'B-MISC'},\n"," {'form': 'lamb', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'},\n"," {'form': '.', 'ppos': '.', 'pchunk': 'O', 'ner': 'O'}]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["train_sentences = read_sentences(train_file)\n","train_dict = split_rows(train_sentences, column_names)\n","\n","val_sentences = read_sentences(val_file)\n","val_dict = split_rows(val_sentences, column_names)\n","\n","train_dict[1]"]},{"cell_type":"markdown","metadata":{"id":"tGmc396x6Fdr"},"source":["## Embeddings"]},{"cell_type":"markdown","metadata":{"id":"wbtSbbkK6Fds"},"source":["### Reading the embeddings"]},{"cell_type":"markdown","metadata":{"id":"BdSYCrv56Fds"},"source":["Adjust your folders"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"TG2lDPTa6Fds"},"outputs":[],"source":["if EMB_LARGE:\n","    embedding_file = './glove/glove.6B.100d.txt'\n","    EMBEDDING_DIM = 100\n","else:\n","    embedding_file = './glove/glove.6B.50d.txt'\n","    EMBEDDING_DIM = 50"]},{"cell_type":"markdown","metadata":{"id":"ZyPd-a506Fds"},"source":["Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."]},{"cell_type":"code","execution_count":68,"metadata":{"id":"PexOHX3y6Fds"},"outputs":[],"source":["def read_embeddings(file):\n","    \"\"\"\n","    Return the embeddings in the from of a dictionary\n","    :param file:\n","    :return:\n","    \"\"\"\n","    embeddings = {} # Create embedding dictionary\n","    glove = open(file, encoding='utf8') # open embedding file\n","    for line in glove: # for word and embedding\n","        values = line.strip().split() #removes leading or trailing whitespaces and then splits by whitespace, giving a list of each value in a embedding\n","        word = values[0] # word = first position\n","        vector = torch.FloatTensor(list(map(float, values[1:]))) # vector embedding is remaining values\n","        embeddings[word] = vector #put word and vector in dictionary\n","    glove.close()\n","    return embeddings"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"O2j59mVu6Fds"},"outputs":[],"source":["# We read the embeddings\n","embeddings_dict = read_embeddings(embedding_file)\n","embedded_words = sorted(list(embeddings_dict.keys()))"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"B-3kwWxM6Fds"},"outputs":[{"data":{"text/plain":["'# words in embedding dictionary: 400000'"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["'# words in embedding dictionary: {}'.format(len(embedded_words))"]},{"cell_type":"markdown","metadata":{"id":"8rynjkcj6Fds"},"source":["### Understanding the embeddings"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"AhAs4CJ26Fds"},"outputs":[{"data":{"text/plain":["['chording',\n"," 'chordoma',\n"," 'chordophones',\n"," 'chords',\n"," 'chore',\n"," 'chorea',\n"," 'chorene',\n"," 'choreograph',\n"," 'choreographed',\n"," 'choreographer']"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["embedded_words[100000:100010]"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"rGeYZSyu6Fds"},"outputs":[{"data":{"text/plain":["tensor([-0.5197,  1.0395,  0.2092,  0.1629,  0.7209,  0.8152, -0.3464, -0.7665,\n","        -0.4958,  0.2463,  0.4409,  0.3770, -0.1640,  0.2775,  0.1656,  0.4387,\n","        -1.0887,  0.1266,  0.6692,  0.3578])"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["embeddings_dict['chords'][:20]"]},{"cell_type":"markdown","metadata":{"id":"ICPyYhkB6Fds"},"source":["#### Embedding Matrix\n","For the vectors in `embeddings_dict`, create a unique `E` matrix of the embeddings. To keep track of the word index, create also an `emb_word_idx` dictionary that will associate the row index its corresponding word.\n","\n","To build `E`, you may first store the vectors in a list and then use `torch.stack()` to convert it in a tensor."]},{"cell_type":"code","execution_count":73,"metadata":{"id":"mXJNycec6Fdy"},"outputs":[],"source":["# Write your code\n","E = []\n","emb_word_idx = {}\n","index = 0\n","for index, (key, values) in enumerate(embeddings_dict.items()):\n","    E.append(values)\n","    emb_word_idx[index] = key\n","    index += 1\n","E = torch.stack(E)\n"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"ABGpzJsd6Fdy"},"outputs":[{"data":{"text/plain":["'chords'"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["emb_word_idx[21359]"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"WMkp1o_z6Fdy"},"outputs":[{"data":{"text/plain":["tensor([-0.5197,  1.0395,  0.2092,  0.1629,  0.7209,  0.8152, -0.3464, -0.7665,\n","        -0.4958,  0.2463,  0.4409,  0.3770, -0.1640,  0.2775,  0.1656,  0.4387,\n","        -1.0887,  0.1266,  0.6692,  0.3578])"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["E[21359][:20]"]},{"cell_type":"markdown","metadata":{"id":"EgU7bvue6Fdy"},"source":["Normalize the rows so that each row has a norm of 1"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"eKuy_YKq6Fdz"},"outputs":[],"source":["# Write your code here\n","E = F.normalize(E, dim=1) # Normalises over rows in E."]},{"cell_type":"markdown","metadata":{"id":"v6Qd97vl6Fdz"},"source":["Using a cosine similarity, write a `closest(target_word_embeddings, embeddings, count=10)` that computes the 10 closest rows of a given vector `target_word_embeddings`.\n","\n","Remember that:\n","$$\n","\\cos(\\mathbf{u}, \\mathbf{v}) = \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{||\\mathbf{u}|| ||\\mathbf{v}||}\n","$$"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"jSvOeJfg6Fdz"},"outputs":[],"source":["# Write your code here\n","def closest(target_word_emb, E, count=10):\n","    # target_word_emb = F.normalize(target_word_emb.unsqueeze(0), p=2, dim=1).squeeze(0)\n","    similarity = []\n","    for embedding in E:\n","        if not torch.all(target_word_emb.eq(embedding)):\n","            cos = torch.dot(target_word_emb, embedding)/(torch.norm(target_word_emb)*torch.norm(embedding))\n","            similarity.append(cos.item())\n","\n","    enumerateted_similarity = list(enumerate(similarity)) # add index to cosine similarity\n","    sorted_list = sorted(enumerateted_similarity, key=lambda x: x[1], reverse=True) # sort by similarity in DESC order\n","    # print(enumerateted_similarity)\n","    # print(sorted_list)\n","\n","    closest_indices = [x[0] for x in sorted_list[:count]] # extract indices for first ten similarities.\n","    # print(closest_indices)\n","    return closest_indices\n","\n","    # print(similarity)"]},{"cell_type":"markdown","metadata":{"id":"jv13FCfg6Fdz"},"source":["Using the `closest()` function find the words closest to _table_, _france_, and _sweden_."]},{"cell_type":"code","execution_count":78,"metadata":{"id":"72gNQbLI6Fdz"},"outputs":[{"data":{"text/plain":["tensor([-0.6145,  0.8969,  0.5677,  0.3910, -0.2244,  0.4904,  0.1087,  0.2741,\n","        -0.2383, -0.5215,  0.7355, -0.3265,  0.5130,  0.3241, -0.4671,  0.6805,\n","        -0.2550, -0.0405, -0.5442, -1.0548])"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["embeddings_dict['table'][:20]"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"wxjPAVoF6Fdz"},"outputs":[{"data":{"text/plain":["[1801, 7221, 241, 2389, 927, 437, 3162, 220, 187, 3216]"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["closest(embeddings_dict['table'], E, count=10)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"1E9Lw0Yj6Fdz"},"outputs":[{"data":{"text/plain":["['table',\n"," 'tables',\n"," 'place',\n"," 'bottom',\n"," 'room',\n"," 'side',\n"," 'sit',\n"," 'top',\n"," 'here',\n"," 'pool']"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["list(map(emb_word_idx.get, closest(embeddings_dict['table'], E, count=10)))"]},{"cell_type":"markdown","metadata":{"id":"mfXBDwnS6Fdz"},"source":["## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"]},{"cell_type":"markdown","metadata":{"id":"I0obEOAR6Fdz"},"source":["For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the NER tags.\n","\n","Write a `build_sequences(corpus_dict, key_x='form', key_y='ner', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."]},{"cell_type":"markdown","metadata":{"id":"_pv1Hbbp6Fdz"},"source":["For the 2nd sentence of the training set, you should have:<br/>\n","`x = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']`\n","\n","`y = ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']`"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"YJCTa7s86Fdz"},"outputs":[],"source":["# Write your code\n","def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n","   # column_names = [key_x, key_y]\n","   x = []\n","   y = []\n","   for i in range(len(corpus_dict)):\n","      seq = corpus_dict[i]\n","      if tolower:\n","         x.append([d[key_x].lower() for d in seq])\n","         y.append([d[key_y] for d in seq])\n","      else:\n","         x.append([d[key_x] for d in seq])\n","         y.append([d[key_y] for d in seq])\n","      # print(\"\\n\", x)\n","      # print(\"\\n\", y)\n","   return x, y"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"fJZkICCE6Fd0"},"outputs":[],"source":["X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='ner')\n","X_val_symbs, Y_val_symbs = build_sequences(val_dict, key_x='form', key_y='ner')"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"xu4JMVwo6Fd0"},"outputs":[{"data":{"text/plain":["['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["X_train_symbs[1]"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"lY7q7Yqf6Fd0"},"outputs":[{"data":{"text/plain":["['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["Y_train_symbs[1]"]},{"cell_type":"markdown","metadata":{"id":"odNhsVZq6Fd0"},"source":["## Vocabulary"]},{"cell_type":"markdown","metadata":{"id":"zMCL3Lbp6Fd0"},"source":["Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 402,595 different words. You will proceed in two steps.\n","\n","First extract the list of unique words `words` from the CoNLL training set and the list of NER tags, `ner`. You will sort them"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"76ItXUVK6Fd0"},"outputs":[],"source":["# Write your code: List of words and tags in CoNLL\n","\n","words = []\n","\n","for sentence in X_train_symbs:\n","    for word in sentence:\n","        words.append(word)\n","\n","words = sorted(list(set(words)), reverse=False) #to remove eventual duplicates\n","\n","tags = []\n","for sentence in Y_train_symbs:\n","    for tag in sentence:\n","        if tag not in tags:\n","            tags.append(tag)\n","tags = sorted(list(set(tags)), reverse=False) #to remove eventual duplicates"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"NK6oNxco6Fd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["# words seen in training corpus: 21010\n","# NER tags seen: 9\n"]}],"source":["print('# words seen in training corpus:', len(words))\n","print('# NER tags seen:', len(tags))"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"fZ_gVJoo6Fd0"},"outputs":[{"data":{"text/plain":["['adequate',\n"," 'adige',\n"," 'adj',\n"," 'adjourned',\n"," 'adjust',\n"," 'adjusted',\n"," 'adjusting',\n"," 'adjustments',\n"," 'adkins',\n"," 'administer']"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["words[4000:4010]"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"f671amWS6Fd0"},"outputs":[{"data":{"text/plain":["['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["tags[:10]"]},{"cell_type":"markdown","metadata":{"id":"apUaIqKQ6Fd0"},"source":["Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"YaKXSDv56Fd1"},"outputs":[],"source":["# Write your code: Add vocabulary of embedded words\n","vocabulary_words = embedded_words\n","\n","for sentence in X_train_symbs:\n","    for word in sentence:\n","        vocabulary_words.append(word)\n","\n","vocabulary_words = sorted(list(set(vocabulary_words)), reverse=False) #to remove eventual duplicates"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"f-s8KmD16Fd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["# words in the vocabulary: embeddings and corpus: 402595\n"]}],"source":["print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"V2e7hbOS6Fd1"},"outputs":[{"data":{"text/plain":["['jmurray',\n"," 'jmw',\n"," 'jmy',\n"," 'jn',\n"," 'jn-4',\n"," 'jna',\n"," 'jnana',\n"," 'jnanpith',\n"," 'jnc',\n"," 'jne']"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["vocabulary_words[200000:200010]"]},{"cell_type":"markdown","metadata":{"id":"TbKiU3o-6Fd1"},"source":["## Index"]},{"cell_type":"markdown","metadata":{"id":"zbyR7TF36Fd1"},"source":["Create the indices `word2idx`, `tag2idx` and inverted indices `idx2word`, `idx2tag` for the words and the tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the tags, you will start at index 1."]},{"cell_type":"code","execution_count":92,"metadata":{"id":"TQX6JQm56Fd1"},"outputs":[],"source":["# Write your code:\n","padding_symbol = \"0\"\n","word2idx = {word: index for index, word in enumerate(vocabulary_words, start=2)}\n","word2idx[padding_symbol] = 0\n","\n","tag2idx = {tag: index for index, tag in enumerate(tags, start=1)}\n","idx2word = {index: word for word, index in word2idx.items()}\n","# word2idx[\"unknown\"] = 1\n","idx2tag = {index: tag for tag, index in tag2idx.items()}"]},{"cell_type":"markdown","metadata":{"id":"VgegKGG96Fd1"},"source":["The word indices"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"OBgd2qA26Fd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"]}],"source":["print(list(word2idx.items())[:25])"]},{"cell_type":"markdown","metadata":{"id":"MG4rzVgx6Fd1"},"source":["The tag indices"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"ZnAD2Ykm6Fd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'B-LOC': 1, 'B-MISC': 2, 'B-ORG': 3, 'B-PER': 4, 'I-LOC': 5, 'I-MISC': 6, 'I-ORG': 7, 'I-PER': 8, 'O': 9}\n"]}],"source":["print(tag2idx)"]},{"cell_type":"markdown","metadata":{"id":"ga-UMbmG6Fd2"},"source":["## Embedding Matrix"]},{"cell_type":"markdown","metadata":{"id":"RWsrqaV06Fd2"},"source":["Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n","The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1.\n","\n","Initialize the matrix with random values with the `torch.rand()`"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"SdZFwhag6Fd2"},"outputs":[],"source":["# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n","embedding_matrix = torch.rand((len(vocabulary_words) + 2, EMBEDDING_DIM))/10 - 0.05 # range: -0.05, 0.05,\n","# embedding_matrix = torch.rand((len(vocabulary_words) + 2, EMBEDDING_DIM))\n","# embedding_matrix = torch.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"]},{"cell_type":"markdown","metadata":{"id":"piYo3EvC6Fd2"},"source":["The shape of your matrix is: (402597, 100) or (402597, 50)"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"zbuR_Qv36Fd2"},"outputs":[{"data":{"text/plain":["torch.Size([402597, 100])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix.shape"]},{"cell_type":"markdown","metadata":{"id":"UDN9zn8c6Fd2"},"source":["Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."]},{"cell_type":"code","execution_count":97,"metadata":{"id":"Bi01OlSz6Fd2"},"outputs":[],"source":["# Write your code\n","out_of_embeddings = []\n","\n","for word in vocabulary_words:\n","    index = word2idx[word] # extract index of word in embedding index\n","    try:\n","        embedding_matrix[index] = embeddings_dict[word] # replace values in\n","    except KeyError:\n","        out_of_embeddings.append(word) # if word in in embeddings_dict add to out_of_embeddings\n","# out_of_embeddings = list(set(out_of_embeddings))\n","out_of_embeddings = sorted(list(set(out_of_embeddings)), reverse=False)"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"EkcuSjuD6Fd2"},"outputs":[{"data":{"text/plain":["2595"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["len(out_of_embeddings)"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"ivAJA7UZ6Fd2"},"outputs":[{"data":{"text/plain":["['zelezarny',\n"," 'zhilan',\n"," 'zieger',\n"," 'zighayer',\n"," 'zilinskiene',\n"," 'zirka-nibas',\n"," 'zuleeg',\n"," 'zundra',\n"," 'zwingmann',\n"," 'zyrecha']"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["out_of_embeddings[-10:]"]},{"cell_type":"markdown","metadata":{"id":"dcucc5Ua6Fd2"},"source":["Embeddings of the padding symbol, idx 0, random numbers"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"JeEtWVOw6Fd3"},"outputs":[{"data":{"text/plain":["tensor([-0.6149,  0.9273,  0.5583,  0.0057, -0.6717,  0.6119,  0.9923,  0.2764,\n","        -0.6489, -0.5167])"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix[0][:10]"]},{"cell_type":"markdown","metadata":{"id":"B9av7CI36Fd3"},"source":["Embeddings of the word _table_, the GloVe values"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"C7CXktWZ6Fd3"},"outputs":[{"data":{"text/plain":["tensor([-0.6145,  0.8969,  0.5677,  0.3910, -0.2244,  0.4904,  0.1087,  0.2741,\n","        -0.2383, -0.5215])"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix[word2idx['table']][:10]"]},{"cell_type":"markdown","metadata":{"id":"aCirQ3Ao6Fd3"},"source":["Embeddings of _zarett_, a word in CoNLL 2003, but not in GloVe, random numbers"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"zp1Q8tOM6Fd3"},"outputs":[{"data":{"text/plain":["tensor([-0.0150,  0.0476,  0.0197, -0.0334, -0.0267,  0.0237,  0.0041, -0.0454,\n","         0.0163,  0.0111])"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix[word2idx['zwingmann']][:10]"]},{"cell_type":"markdown","metadata":{"id":"IofImd6h6Fd3"},"source":["## Creating the ${X}$ and ${Y}$ Sequences"]},{"cell_type":"markdown","metadata":{"id":"dQyQXxzI6Fd3"},"source":["You will now create the input and output sequences with numerical indices. First, convert the\n","${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$\n","lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."]},{"cell_type":"code","execution_count":103,"metadata":{"id":"QD51RMv96Fd3"},"outputs":[],"source":["# Write your code\n","# We create the parallel sequences of indexes\n","def mapword(x):\n","    try:\n","        index = word2idx[x]\n","        return index\n","    except KeyError:\n","        return 1\n","\n","def maptag(x):\n","    try:\n","        index = tag2idx[x]\n","        return index\n","    except KeyError:\n","        return 0\n","\n","# X_train_idx = [mapword(word) for sentences in X_train_symbs for word in sentences]\n","X_train_idx = [list(map(lambda x: mapword(x), sentence)) for sentence in X_train_symbs]\n","Y_train_idx = [list(map(lambda x: maptag(x), sentence)) for sentence in Y_train_symbs]\n","# Y_train_idx = [tag2idx[tag] for sentences in Y_train_symbs for tag in sentences]"]},{"cell_type":"markdown","metadata":{"id":"TWIw1MdA6Fd3"},"source":["Do the same for the validation set. Be aware that some words may be unknown."]},{"cell_type":"code","execution_count":104,"metadata":{"id":"3L0WNRpn6Fd3"},"outputs":[],"source":["# Write your code\n","# We create the parallel sequences of indexes\n","X_val_idx = [list(map(lambda x: mapword(x), sentence)) for sentence in X_val_symbs]\n","Y_val_idx = [list(map(lambda x: maptag(x), sentence)) for sentence in Y_val_symbs]\n","\n","# for sentence in X_val_symbs:\n","#         indexes = list(map(lambda x: mapword(x), sentence))\n","#         X_val_idx.append(indexes)\n","\n","# for sentence in Y_val_symbs:\n","#         indexes = list(map(lambda x: maptag(x), sentence))\n","#         Y_val_idx.append(indexes)\n"]},{"cell_type":"markdown","metadata":{"id":"fA3WhHtW6Fd3"},"source":["Word indices of the three first sentences"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"IPAS4uJa6Fd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[935], [142143, 307143, 161836, 91321, 363368, 83766, 85852, 218260, 936], [284434, 79019]]\n","[[935], [113351, 679, 221875, 354360, 275584, 63471, 364505, 49150, 192163, 381011, 936], [227217, 15431]]\n"]}],"source":["print(X_train_idx[:3])\n","print(X_val_idx[:3])"]},{"cell_type":"markdown","metadata":{"id":"U2s4nTN46Fd3"},"source":["NER tag indices of the three first sentences"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"_flPld3I6Fd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[9], [3, 9, 2, 9, 9, 9, 2, 9, 9], [4, 8]]\n","[[9], [9, 9, 3, 9, 9, 9, 9, 9, 9, 9, 9], [1, 9]]\n"]}],"source":["print(Y_train_idx[:3])\n","print(Y_val_idx[:3])"]},{"cell_type":"markdown","metadata":{"id":"KPFdUbbg6Fd3"},"source":["Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n","\n","\n","```\n","x = tensor([142143, 307143, 161836,  91321, 363368,  83766,  85852, 218260,    936,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0])\n","y = tensor([3, 9, 2, 9, 9, 9, 2, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","```\n","\n","You will call the results `X_train_padded` and `Y_train_padded`. Do the same for the validation set."]},{"cell_type":"code","execution_count":107,"metadata":{"id":"vJHYMDGS6Fd4"},"outputs":[],"source":["X_train_idx = list(map(torch.LongTensor, X_train_idx))\n","Y_train_idx = list(map(torch.LongTensor, Y_train_idx))\n","\n","X_val_idx = list(map(torch.LongTensor, X_val_idx))\n","Y_val_idx = list(map(torch.LongTensor, Y_val_idx))"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"grcxNwK46Fd4"},"outputs":[],"source":["# Write your code here\n","X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n","Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)\n","\n","X_val_padded = pad_sequence(X_val_idx, batch_first=True)\n","Y_val_padded = pad_sequence(Y_val_idx, batch_first=True)"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"QBvDhwVr6Fd4"},"outputs":[{"data":{"text/plain":["tensor([142143, 307143, 161836,  91321, 363368,  83766,  85852, 218260,    936,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0])"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["X_train_padded[1]"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"UKEFkG556Fd4"},"outputs":[{"data":{"text/plain":["tensor([3, 9, 2, 9, 9, 9, 2, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["Y_train_padded[1]"]},{"cell_type":"markdown","metadata":{"id":"3EbjKUIV6Fd4"},"source":["## Network Architecture"]},{"cell_type":"markdown","metadata":{"id":"q06zQV_K6Fd4"},"source":["Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."]},{"cell_type":"code","execution_count":111,"metadata":{"id":"oEPqCrKr9ZI3"},"outputs":[],"source":["class RNNModel(nn.Module):\n","\n","    def __init__(self, embedding_matrix, rnn_units, nbr_classes, freeze_embs=True, num_layers=1, bidi_lstm=True):\n","        super().__init__()\n","        self.emb_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=freeze_embs)\n","        self.dropout_layer = nn.Dropout(p=DROPOUT, inplace=False)\n","        self.rnn_layer = nn.RNN(input_size=embedding_matrix.size(1), dropout=DROPOUT, hidden_size=rnn_units, batch_first=True, num_layers=num_layers, bidirectional=bidi_lstm)\n","        self.dropout_layer_2 = nn.Dropout(p=DROPOUT, inplace=False)\n","        rnn_units = rnn_units if not bidi_lstm else rnn_units * 2\n","        self.linear = nn.Linear(rnn_units, nbr_classes)\n","        # self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.emb_layer(x)\n","        x = self.dropout_layer(x)\n","        x, _ = self.rnn_layer(x)\n","        x = F.relu(x)\n","        x = self.dropout_layer_2(x)\n","        x = self.linear(x)\n","        # output = self.softmax(x)\n","        output = x\n","        return output"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"yopDUW3P6Fd4"},"outputs":[],"source":["# Write your code\n","class Model(nn.Module):\n","\n","    def __init__(self, embedding_matrix, lstm_units, nbr_classes, freeze_embs=True, num_layers=1, bidi_lstm=False):\n","        super().__init__()\n","        self.emb_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=freeze_embs, padding_idx=0)\n","        self.dropout_layer = nn.Dropout(p=DROPOUT, inplace=False)\n","        self.lstm_layer = nn.LSTM(input_size=embedding_matrix.size(1), dropout=DROPOUT, hidden_size=lstm_units, batch_first=True, num_layers=num_layers, bidirectional=bidi_lstm)\n","\n","        l = lstm_units if not bidi_lstm else lstm_units * 2\n","\n","        self.linear = nn.Linear(l, nbr_classes)\n","        # self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.emb_layer(x)\n","        x = self.dropout_layer(x)\n","        x, _ = self.lstm_layer(x)\n","        x = F.leaky_relu(x)\n","        #x = F.relu(x)\n","        x = self.dropout_layer(x)\n","        x = self.linear(x)\n","\n","        #output = self.softmax(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"WmR0_uCp6Fd4"},"source":["Create your model"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"5ZCf9IjA6Fd4"},"outputs":[],"source":["if LSTM:\n","    model = Model(embedding_matrix,\n","                LSTM_HIDDEN_DIM,\n","                len(tags) + 1,\n","                freeze_embs=FREEZE_EMBS,\n","                num_layers=LSTM_LAYERS,\n","                bidi_lstm=True)\n","else:\n","    model = RNNModel(embedding_matrix,\n","                LSTM_HIDDEN_DIM,\n","                len(tags) + 1,\n","                freeze_embs=FREEZE_EMBS,\n","                num_layers=LSTM_LAYERS,)"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"data":{"text/plain":["Model(\n","  (emb_layer): Embedding(402597, 100, padding_idx=0)\n","  (dropout_layer): Dropout(p=0.4, inplace=False)\n","  (lstm_layer): LSTM(100, 98, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n","  (linear): Linear(in_features=196, out_features=10, bias=True)\n",")"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["if not RETRAIN:\n","    if LSTM:\n","        state_dict = torch.load(f\"./outputs/LSTM/LSTM_model_{MOD}.pth\", map_location=torch.device('cpu'))\n","    else:\n","        state_dict = torch.load(f\"./outputs/RNN/RNN_model_{MOD}.pth\", map_location=torch.device('cpu'))\n","    model.load_state_dict(state_dict)\n","model.eval()"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"9uLY40lL6Fd4"},"outputs":[{"data":{"text/plain":["Model(\n","  (emb_layer): Embedding(402597, 100, padding_idx=0)\n","  (dropout_layer): Dropout(p=0.4, inplace=False)\n","  (lstm_layer): LSTM(100, 98, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n","  (linear): Linear(in_features=196, out_features=10, bias=True)\n",")"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["model\n","#device = torch.device(\"cuda:0\")\n","device = torch.device(\"mps\")\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"f5mahFW_6Fd4"},"source":["Write the loss `loss_fn` and optimizer `optimizer`.\n","\n","Note that to compute the loss, you need to discard the padding symbols from the results and specify their index\n","https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html (ignore_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qFR1AD16Fd4"},"outputs":[],"source":["# Write your code\n","loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n","optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n","loss_fn.to(device)"]},{"cell_type":"markdown","metadata":{"id":"GQqucg3y6Fd5"},"source":["## Data Loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRJsKEPs6Fd5"},"outputs":[],"source":["X_train = torch.LongTensor(X_train_padded).to(device)\n","Y_train = torch.LongTensor(Y_train_padded).to(device)\n","\n","X_val = torch.LongTensor(X_val_padded).to(device)\n","Y_val = torch.LongTensor(Y_val_padded).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlrlIq576Fd5"},"outputs":[],"source":["dataset = TensorDataset(X_train, Y_train)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"otMfw6iZ6Fd5"},"source":["## A Few Experiments\n","\n","### Flattening the tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bB1jp2a6Fd5"},"outputs":[],"source":["Y_train.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGFkiVX46Fd5"},"outputs":[],"source":["Y_train.view(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49-ysIvf6Fd5"},"outputs":[],"source":["Y_train.view(-1).size()"]},{"cell_type":"markdown","metadata":{"id":"UqAuBvJU6Fd5"},"source":["### Applying the Model"]},{"cell_type":"markdown","metadata":{"id":"sbp6uWSp6Fd5"},"source":["We apply the model to the whole training set. You can do it in one shot with the statements below. This can use up all your memory. Do not do it you do not have a lot of memory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnHjEtXA6Fd5"},"outputs":[],"source":["if RETRAIN:\n","    if LARGE_MEM:\n","        with torch.no_grad():\n","            Y_train_pred = model(X_train)"]},{"cell_type":"markdown","metadata":{"id":"O-rq8Utx6Fd5"},"source":["It is prefereble to use smaller batches instead. This is less legible but safer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f5g6Qy06Fd5"},"outputs":[],"source":["def batch_inference(model, X, batchsize=2048): # Original batch size 2048\n","     with torch.no_grad():\n","         partial = []\n","         for i in range(0, X.shape[0], batchsize):\n","             partial.append(model(X[i:i+batchsize].to(device)))\n","\n","     return torch.vstack(partial)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyqR-fSv6Fd5"},"outputs":[],"source":["if RETRAIN:\n","    if not LARGE_MEM:\n","        Y_train_pred = batch_inference(model, X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"san7xz-n6Fd5"},"outputs":[],"source":["if RETRAIN:\n","    Y_train_pred.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYKnxIq86Fd5"},"outputs":[],"source":["if RETRAIN:\n","    Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"]},{"cell_type":"markdown","metadata":{"id":"iLIITbO06Fd6"},"source":["## Training the Model"]},{"cell_type":"markdown","metadata":{"id":"hXCHPfaI6Fd6"},"source":["We create a dictionary to store the accuracy and the loss. You will compute them in the training loop. You should exclude the the padding symbols from your counts. To do this, use a multiplicative mask with the terms Y_train > 0 or Y_val > 0. This is not critical though as you will evaluate the final results with another script."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0b2IgPo6Fd6"},"outputs":[],"source":["history = {}\n","history['accuracy'] = []\n","history['loss'] = []\n","history['val_accuracy'] = []\n","history['val_loss'] = []"]},{"cell_type":"markdown","metadata":{"id":"pwSD2JY56Fd6"},"source":["We fit the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QqsGI71e6Fd6"},"outputs":[],"source":["# Write your code\n","if RETRAIN:\n","    for epoch in range(EPOCHS):\n","        train_loss = 0\n","        train_accuracy = 0\n","        val_loss = 0\n","        val_accuracy = 0\n","        word_cnt = 0\n","        batch_cnt = 0\n","        train_correct = 0\n","        total_samples = 0\n","        model.train()\n","\n","        # TRAINING\n","        loop = tqdm(dataloader, desc=f'Epoch {epoch+1}/{EPOCHS}', leave=True)\n","        for data, target in loop:\n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            output = model(data)\n","\n","            loss = loss_fn(output.view(-1, output.shape[-1]), target.view(-1))\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            # train_correct += torch.sum(torch.mul(torch.argmax(output, dim=-1) == target, target > 0)) # Does not compare with unknown words\n","            predicted = torch.argmax(output, dim=-1)\n","            train_correct += torch.sum(torch.eq(predicted, target))\n","\n","            total_samples += data.size(0)\n","            loop.set_postfix(loss=train_loss/total_samples, accuracy=train_correct/total_samples)\n","            batch_cnt += 1\n","\n","        # EVAL\n","        model.eval()\n","        with torch.no_grad():\n","            acc = torch.sum(torch.mul(torch.argmax(batch_inference(model, X_train), dim=-1) == Y_train, Y_train > 0)) # Does not compare with unknown words\n","\n","            history['accuracy'] += [acc.item()/torch.sum(Y_train > 0)]\n","            history['loss'] += [train_loss/batch_cnt]\n","\n","            y_val_pred =  model(X_val)\n","            loss = loss_fn(y_val_pred.view(-1,y_val_pred.shape[-1]), Y_val.view(-1))\n","            history['val_loss'] += [loss.item()]\n","            acc = torch.sum(torch.mul(torch.argmax(model(X_val), dim=-1) == Y_val, Y_val > 0))\n","            history['val_accuracy'] += [acc.item()/torch.sum(Y_val > 0)]\n","        torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"3BRRWrLR6Fd6"},"source":["And we visualize the training curves. We compare them with a validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6aJiu0m6Fd6"},"outputs":[],"source":["if RETRAIN:\n","    acc = [value.cpu() if isinstance(value, torch.Tensor) else value for value in history['accuracy']]\n","    loss = [value.cpu() if isinstance(value, torch.Tensor) else value for value in history['loss']]\n","    val_acc = [value.cpu() if isinstance(value, torch.Tensor) else value for value in history['val_accuracy']]\n","    val_loss = [value.cpu() if isinstance(value, torch.Tensor) else value for value in history['val_loss']]\n","\n","    print(len(acc))\n","    print(len(val_acc))\n","\n","    epochs = range(1, len(acc) + 1)\n","    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","    plt.title('Training and validation accuracies')\n","    plt.legend()\n","\n","    plt.figure()\n","    plt.plot(epochs, loss, 'bo', label='Training loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation losses')\n","    plt.legend()\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iH0i91o_6Fd6"},"outputs":[],"source":["# if not RETRAIN:\n","#     state_dict = torch.load(\"./outputs/LSTM/LSTM_model_2.pth\", map_location=torch.device('cpu'))\n","#     model.load_state_dict(state_dict)\n","# model.eval()"]},{"cell_type":"markdown","metadata":{"id":"1ob1K_Hk6Fd6"},"source":["We try the model on a test sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hbTqh1-6Fd6"},"outputs":[],"source":["sentence = 'The United States might collapsez .'.lower().split()"]},{"cell_type":"markdown","metadata":{"id":"bYKhejAT6Fd6"},"source":["Convert the sentence words to indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OazTlQ-g6Fd6"},"outputs":[],"source":["# Write your code\n","# The indexes or the unknown word idx\n","sentence_word_idxs = [mapword(word) for word in sentence]\n","print(sentence_word_idxs)"]},{"cell_type":"markdown","metadata":{"id":"q889mZJO6Fd6"},"source":["The indices. Note the 1 at the end."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mlv3yh-j6Fd6"},"outputs":[],"source":["print('Sentence', sentence)\n","print('Sentence word indexes', sentence_word_idxs)"]},{"cell_type":"markdown","metadata":{"id":"z4RnANax6Fd7"},"source":["Predict the tags. Call the variable `sent_tag_predictions`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MC7gMlD26Fd7"},"outputs":[],"source":["# Write your code\n","sentence_word_idxs = torch.tensor(sentence_word_idxs, dtype=torch.long).to(device)\n","sent_tag_predictions = model(sentence_word_idxs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIYEmIsI6Fd7"},"outputs":[],"source":["sent_tag_predictions.shape"]},{"cell_type":"markdown","metadata":{"id":"9V1KMJCv6Fd7"},"source":["The estimated probabilities of the first tag"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h92GXcPN6Fd7"},"outputs":[],"source":["F.softmax(sent_tag_predictions[0], dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzItM7C96Fd7"},"outputs":[],"source":["torch.argmax(F.softmax(sent_tag_predictions, dim=-1), dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"ZrnfhzDJ6Fd7"},"source":["We apply argmax to select the tag"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kk2Eq0Za6Fd7"},"outputs":[],"source":["for word_nbr, tag_predictions in enumerate(sent_tag_predictions):\n","    if int(sentence_word_idxs[word_nbr]) in idx2word:\n","        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n","    else:\n","        print(sentence[word_nbr], '/ukn', end=': ')\n","    print(idx2tag.get(int(torch.argmax(F.softmax(tag_predictions, dim=-1), dim=-1))))"]},{"cell_type":"markdown","metadata":{"id":"xQFmD0lz6Fd7"},"source":["## Evaluating the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"180shd-L6Fd7"},"outputs":[],"source":["test_sentences = read_sentences(test_file)\n","test_dict = split_rows(test_sentences, column_names)\n","test_dict[1:2]"]},{"cell_type":"markdown","metadata":{"id":"ElI5Egyz6Fd7"},"source":["We create the ${X}$ and ${Y}$ sequences of symbols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNsNwDSX6Fd7"},"outputs":[],"source":["X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='ner')\n","print('X_test:', X_test_symbs[1])\n","print('Y_test', Y_test_symbs[1])"]},{"cell_type":"markdown","metadata":{"id":"2IsjLKC16Fd7"},"source":["Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRjkO4AF6Fd7"},"outputs":[],"source":["# Write your code\n","X_test_idx = []\n","for x in X_test_symbs:\n","    # We map the unknown words to index 1\n","    x_idx = list(map(lambda a: word2idx.get(a, 1), x))\n","    X_test_idx += [x_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1iu4Bud6Fd-"},"outputs":[],"source":["X_test_idx = map(torch.LongTensor, X_test_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3ceIj-X6Fd-"},"outputs":[],"source":["X_test_padded = pad_sequence(X_test_idx, batch_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrUtuI_x6Fd-"},"outputs":[],"source":["print('X_test_padded:', X_test_padded[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3I15qC16Fd-"},"outputs":[],"source":["X_test_padded.shape"]},{"cell_type":"markdown","metadata":{"id":"5DMlEyYd6Fd-"},"source":["Predict the NER tags. Call the result `Y_test_hat_probs`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3r7C-d1g6Fd-"},"outputs":[],"source":["# Write your code\n","Y_test_hat_probs = batch_inference(model, X_test_padded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWffGQg06Fd-"},"outputs":[],"source":["print('Predictions', Y_test_hat_probs[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwBgOvyr6Fd_"},"outputs":[],"source":["Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_c8Vw9w6Fd_"},"outputs":[],"source":["Y_test_hat_probs[1]"]},{"cell_type":"markdown","metadata":{"id":"Qr6KQr1d6Fd_"},"source":["We now predict the whole test set and we store the results in each dictionary with the key `pner`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdIXMPuW6Fd_"},"outputs":[],"source":["for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n","    sent_len = len(sent)\n","    y_hat_probs = y_hat_probs[:sent_len]\n","    y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n","    # y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n","    for word, ner_hat in zip(sent, y_hat):\n","        word['pner'] = idx2tag.get(int(ner_hat))\n","        if word['pner'] == None:\n","            print(sent)"]},{"cell_type":"markdown","metadata":{"id":"oCQDfeXf6Fd_"},"source":["A sentence example: `ner` is the hand annotation and `pner` is the prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eI3a4w9a6Fd_"},"outputs":[],"source":["test_dict[1]"]},{"cell_type":"markdown","metadata":{"id":"UzAUgvhE6Fd_"},"source":["We save the test set in a file to evaluate the performance of our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Sw6Tc2l6Fd_"},"outputs":[],"source":["column_names = ['form', 'ppos', 'pchunk', 'ner', 'pner']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kyDL2ff6Fd_"},"outputs":[],"source":["def save(file, corpus_dict, column_names):\n","    \"\"\"\n","    Saves the corpus in a file\n","    :param file:\n","    :param corpus_dict:\n","    :param column_names:\n","    :return:\n","    \"\"\"\n","    with open(file, 'w', encoding='utf8') as f_out:\n","        for sentence in corpus_dict:\n","            sentence_lst = []\n","            for row in sentence:\n","                items = map(lambda x: str(row.get(x, '_')), column_names)  # Convert to string\n","                sentence_lst.append(' '.join(items) + '\\n')  # Append to list\n","            sentence_lst.append('\\n')  # Add empty line after each sentence\n","            f_out.write(''.join(sentence_lst))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3qj54z56Fd_"},"outputs":[],"source":["\n","if LSTM:\n","    outfile = f'outputs/LSTM/lstm_model_{MOD}.out'\n","else:\n","    outfile = f'outputs/RNN/RNN_model_{MOD}.out'\n","if RETRAIN:\n","    save(outfile, test_dict, column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":718,"status":"ok","timestamp":1715002225887,"user":{"displayName":"Erik Dahlberg","userId":"12485416232887832469"},"user_tz":-120},"id":"wcaVJuO66Fd_","outputId":"69728121-e25c-45ad-e57c-61dcf1b72528"},"outputs":[],"source":["lines = open(outfile, encoding='utf8').read().splitlines()\n","res = conlleval.evaluate(lines)\n","chunker_score = res['overall']['chunks']['evals']['f1']\n","chunker_score\n","\n","# First test of LSTM gave 0.8911 - {'EPOCHS': 10 'LSTM_HIDDEN_DIM': 64,'LSTM_LAYERS': 2, 'DROPOUT': 0.3,'EMB_LARGE': True, 'FREEZE_EMBS': True}\n","# Second test of LSTM gave 0.9079 - {'EPOCHS': 20 'LSTM_HIDDEN_DIM': 98,'LSTM_LAYERS': 3, 'DROPOUT': 0.3,'EMB_LARGE': True, 'FREEZE_EMBS': True}\n","# First test of RNN gave 0.8247 - {'EPOCHS': 10 'RNN_HIDDEN_DIM': 64,'RNN_LAYERS': 2, 'DROPOUT': 0.3,'EMB_LARGE': True, 'FREEZE_EMBS': True}\n","# Second test of RNN gave 0.8533 - {'EPOCHS': 20 'RNN_HIDDEN_DIM': 98,'RNN_LAYERS': 3, 'DROPOUT': 0.4,'EMB_LARGE': True, 'FREEZE_EMBS': True}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1715002335380,"user":{"displayName":"Erik Dahlberg","userId":"12485416232887832469"},"user_tz":-120},"id":"74f5pA-W6FeA","outputId":"958ab585-9426-4989-b269-94694f26580c"},"outputs":[],"source":["if RETRAIN:\n","    config"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1430,"status":"ok","timestamp":1715002240933,"user":{"displayName":"Erik Dahlberg","userId":"12485416232887832469"},"user_tz":-120},"id":"loJneuv36FeA"},"outputs":[],"source":["if RETRAIN:\n","    if LSTM:\n","        torch.save(model.state_dict(), f'/LSTM_model_{MOD}.pth')\n","    else:\n","        torch.save(model.state_dict(), f'/RNN_model_{MOD}.pth')"]},{"cell_type":"markdown","metadata":{"id":"WxHDDC9W6FeA"},"source":["## Experiments"]},{"cell_type":"markdown","metadata":{"id":"90keHJq06FeA"},"source":["You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least two sets of parameters per network. In your report, you will present your results in a table like this one:\n","\n","|Method|Parameters|Score|\n","|------|-----|-----|\n","|Baseline|  xx | xx |\n","|RNN|  xx |xx |\n","|RNN |  xx |xx |\n","|LSTM |  xx |xx |\n","|LSTM |  xx |xx |\n","\n","The baseline is the one from the CoNLL 2003 shared task. See here: https://aclanthology.org/W03-0419.pdf\n","\n","You need to reach 80 to pass the lab"]},{"cell_type":"markdown","metadata":{"id":"rAQ_bmwj6FeA"},"source":["## Turning in your assignment"]},{"cell_type":"markdown","metadata":{"id":"obd0keof6FeA"},"source":["Now your are done with the program. To complete this assignment, you will:\n","1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n","\n","\n","Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n","1. Write directly your text in Canvas, or\n","2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zErFWBcH6FeA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"vscode":{"interpreter":{"hash":"b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"}}},"nbformat":4,"nbformat_minor":0}
